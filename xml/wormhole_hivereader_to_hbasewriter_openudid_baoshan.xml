<?xml version="1.0" encoding="UTF-8"?>

<job id="hivereader_to_hbasewriter_job">
  <reader>
    <plugin>hivereader</plugin>
    <!--
default:jdbc:hive://10.1.1.161:10000/default
description:hive path ,format like "jdbc:hive://192.168.7.80:10000/default"
mandatory:true
name:path
-->
    <path>jdbc:hive://10.1.1.161:10000/bi</path>
    <!--
description:hive login name
mandatory:false
name:username
-->
    <username></username>
    <!--
description:hive login password
mandatory:false
name:password
-->
    <password></password>
    <!--
default:
range:
description:self-defined sql statement
mandatory:true
name:sql
-->
    <sql>select b.openudid,a.dpid from  bi.dpdim_dpid_cache_daily a join bi.dpdim_openudid_dpid_mapping  b on a.dpid=b.dpid  and b.valid_end_dt='3000-12-31'</sql>

    <!--
default:READ_FROM_HIVESERVER
range:READ_FROM_HIVESERVER,READ_FROM_HDFS
description:query mode, READ_FROM_HIVESERVER: fetch data directly from hive server, READ_FROM_HDFS: insert the data into hdfs directory and fetch data directly from datanode
mandatory:true
name:mode
-->
    <mode>READ_FROM_LOCAL</mode>
    <!--
default:hdfs://10.2.6.102/tmp/
description:the temporary data directory to fetch on hdfs if using mode 2
mandatory:true
name:dataDir
-->
    <dataDir>hdfs://10.2.6.102/tmp/</dataDir>
    <!--
default:-1
range:1-1000
description:reduce task number when doing insert query, when it set to -1, hive will automatically computer reduce number
mandatory:true
name:reduceNumber
-->
    <reduceNumber>-1</reduceNumber>
    <!--
default:1
range:1-10
description:concurrency of the job
mandatory:false
name:concurrency
-->
    <concurrency>5</concurrency>
  </reader>
  <writer>
    <plugin>hbasewriter</plugin>
    <!--
range:
description:hbase table name
mandatory:true
name:htable
-->
    <htable>bi.dpdim_openudid_dpid_mapping</htable>
    <!--
default:false
range:true/false
description:turn on/off autoFlush
mandatory:true
name:autoFlush
-->
    <autoFlush>false</autoFlush>
    <!--
default:1048576
range:[0-26214400]
description:write buffer size
mandatory:true
name:writebufferSize
-->
    <writebufferSize>1048576</writebufferSize>
    <!--
default:true
range:true/false
description:turn on/off wal
mandatory:true
name:writeAheadLog
-->
    <writeAheadLog>true</writeAheadLog>
    <!--
range:
description:specify the rowkey index number
mandatory:true
name:rowKeyIndex
-->
    <rowKeyIndex>0</rowKeyIndex>
    <!--
range:
description:specify the column family and qualifier to write, split by comma, e.g."cf1:col1,cf2:col2"
mandatory:true
name:columnsName
-->
    <columnsName>dim:dpid</columnsName>
    <!--
default:0
range:[0-2]
description:deleteMode before write data into htable, 0:do nothing, 1:delete table data, 2.truncate and create table
mandatory:true
name:deleteMode
-->
    <deleteMode>0</deleteMode>
    <!--
default:0
range:[0-2]
description:rollbackMode when writer failure, 0:do nothing, 1:delete table data, 2.truncate and create table
mandatory:true
name:rollbackMode
-->
    <rollbackMode>0</rollbackMode>
    <!--
default:1
range:1-10
description:concurrency of the job
mandatory:false
name:concurrency
-->
    <concurrency>1</concurrency>
    <!--
description:slow the speed of write
mandatory:false
name:write_sleep
-->
    <write_sleep>false</write_sleep>
    <!--
default:1000
description:wait_time of the write
mandatory:
name:wait_time
-->
    <wait_time>1000</wait_time>
    <!--
default:1000
description:num_to_wait of the write
mandatory:
name:num_to_wait
-->
    <num_to_wait>1000</num_to_wait>
    <!--
description:put row with the given timestamp
mandatory:false
name:putWithTs
-->
    <putWithTs>false</putWithTs>
    <!--
default:5
description:hours to decrease the current_timestamp
mandatory:
name:putTimeStamp
-->
    <secondsDecTimeStamp>3600</secondsDecTimeStamp>
    <!--
default:
description:after insert data, do you want to delete old data
mandatory:false
name:isDeleteData
-->
    <isDeleteData>false</isDeleteData>
	<!--
default:true
description:after insert&delete data, do you want to compact
mandatory:true
name:isMajor_compact
-->
    <isMajor_Compact>true</isMajor_Compact>
    <clusterConfigName>hbase-site-baoshan.xml</clusterConfigName>
  </writer>
</job>
