<?xml version="1.0" encoding="UTF-8"?>

<job id="hivereader_to_hbasewriter_job">
  <reader>
    <plugin>hivereader</plugin>
    <!--
default:jdbc:hive://10.1.1.161:10000/default
description:hive path ,format like "jdbc:hive://192.168.7.80:10000/default"
mandatory:true
name:path
-->
    <path>jdbc:hive://10.1.1.161:10000/bi</path>
    <!--
description:hive login name
mandatory:false
name:username
-->
    <username></username>
    <!--
description:hive login password
mandatory:false
name:password
-->
    <password></password>
    <!--
default:
range:
description:self-defined sql statement
mandatory:true
name:sql
-->
    <!--<sql>select useridcityid,profiles from bi.dpdm_userprofile_for_tg_hbase  where useridcityid is not null and profiles is not null limit 10</sql> -->
    <sql>select user_id,add_date,first_visit_date,last_visit_date,first_app_visit_date,last_app_visit_date,first_tg_date,last_tg_date,first_app_tg_date,last_app_tg_date,open_edm_cnt,click_edm_cnt,dpid_cnt,prefer_tg_cat0,prefer_tg_cat1,prefer_tg_region,prefer_city_id,accuracy,is_tg_zero,is_2014_tg_zero,is_app_tg_zero,save_amt,all_tg_cnt,app_tg_cnt,tg_2013_cnt,tg_2014_cnt,tg_last365_cnt,last_dpid from bi.dprpt_user_profile_service_cdc_snapshot</sql>    
<!--
default:READ_FROM_HIVESERVER
range:READ_FROM_HIVESERVER,READ_FROM_HDFS
description:query mode, READ_FROM_HIVESERVER: fetch data directly from hive server, READ_FROM_HDFS: insert the data into hdfs directory and fetch data directly from datanode
mandatory:true
name:mode
-->
    <mode>READ_FROM_HDFS</mode>
    <!--
default:hdfs://10.2.6.102/tmp/
description:the temporary data directory to fetch on hdfs if using mode 2
mandatory:true
name:dataDir
-->
    <dataDir>hdfs://10.2.6.102/tmp/</dataDir>
    <!--
default:-1
range:1-1000
description:reduce task number when doing insert query, when it set to -1, hive will automatically computer reduce number
mandatory:true
name:reduceNumber
-->
    <reduceNumber>-1</reduceNumber>
    <!--
default:1
range:1-10
description:concurrency of the job
mandatory:false
name:concurrency
-->
    <concurrency>1</concurrency>
  </reader>
  <writer>
    <plugin>rediswriter</plugin>
    <table>bi.dprpt_user_profile_service</table>
    <family>dim</family>
    <keyIndex>0</keyIndex>
    <columnsName>add_date,first_visit_date,last_visit_date,first_app_visit_date,last_app_visit_date,first_tg_date,last_tg_date,first_app_tg_date,last_app_tg_date,open_edm_cnt,click_edm_cnt,dpid_cnt,prefer_tg_cat0,prefer_tg_cat1,prefer_tg_region,prefer_city_id,accuracy,is_tg_zero,is_2014_tg_zero,is_app_tg_zero,save_amt,all_tg_cnt,app_tg_cnt,tg_2013_cnt,tg_2014_cnt,tg_last365_cnt,last_dpid</columnsName>
    <serialize>0</serialize>
    <separator>,</separator>
    <batchSize>300</batchSize>
    <concurrency>5</concurrency>
    <write_sleep>true</write_sleep>
    <wait_time>100</wait_time>
    <num_to_wait>20000</num_to_wait>
  </writer>
</job>
